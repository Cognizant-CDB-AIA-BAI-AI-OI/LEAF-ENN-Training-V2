{
    # The HOCON format is a JSON superset that allows comments
    # and environment variable substitution ... among other things.

    #
    # Small configuration for running ENN session_server and workers locally
    # with minimal external compute and storage dependencies.
    #
    # This config was put together to explain the constraints of the domain and
    # to help others be sure that their setup is working without incurring
    # huge time or money costs.
    #

    "experiment_config": {

        # Name of domain, allows us to determine how data should be loaded
        "domain": "faceAge",

        # Number of generations to run evolution for
        "num_generations": 2,

        # A list of tuples of different fractions of results received and
        # corresponding timeout in seconds.
        "timeout_settings": [[0.8, 3000], [0.9, 2000], [0.95, 1000]],

        # Whether to visualize the best performing network every generation
        # and graph some attributes about the run.
        "visualize": true,

        # Specifies the domain-configuration class's name.
        # File will be found by snake-case of this value.
        "domain_config_class_name": "faceAgeDomainConfig",

        "completion_service": {

            # Number of workers that StudioML will spin up
            "num_workers": 1,

            # List of requirements for worker machines, including number of
            # CPUs, GPUs needed, RAM, HDD space.
            "resources_needed": {
                "cpus": 1,
                "ram": "4g",
                "hdd": "10g",
                "gpus": 0,
                "gpuMem": "5g"
            },

            # Timeout for completion service
            "timeout": 10000,

            # Cloud settings for completion service
            "cloud": null,

            # Whether the completion service is running locally or not
            "local": true,

            # Whether to turn on debug mode or not
            "debug": false,

            "studio_ml_config": {

                # AWS: May 2019, S3 Bucket Name Requirements listed
                # - bucket name can be between 3 and 63 characters long
                # - contain only lower-case characters, numbers, periods, and dashes
                # - Link: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-s3-bucket-naming-requirements.html
                "database": {
                    "type": "s3",
                    "endpoint": ${STUDIO_DATABASE_ENDPOINT},
                    "bucket": ${ENN_USER}-enn-studioml-database,
                    "authentication": "none"
                },
                "storage": {
                    "type": "s3",
                    "endpoint": ${STUDIO_STORAGE_ENDPOINT},
                    "bucket": ${ENN_USER}-enn-studioml-storage
                },
                "queue": "local",
                "saveMetricsFrequency": "1m",
                "saveWorkspaceFrequency": "1m",
                "verbose": "error"
            }
        }
    },

    "domain_config": {

        # Number of tasks to train on for domain (20 by default)
        #$$$$$$$$$$$$$$$ change start $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
        #change num_tasks =1 for multi-class
        "num_tasks": 1,
        #$$$$$$$$$$$$$$$ change end $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
        
        
        # Name of split set to use for determining fitness during evolution,
        # either "val" or "test"
        # "test_dataset": "val",

        # Whether to extract the domain data files in current directory or /tmp/
        "unzip_curr_dir": false,

        # Location of faceGender data files, please change it to your data folder
        #$$$$$$$$$$$$$$$ change start $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
        "data_basedir":/home/ubuntu/Data_face/,
        #$$$$$$$$$$$$$$$ change end $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

        # Number of epochs of training during evaluation
        "num_epochs": 1,

        # Number of minibatches per epoch
        "num_iterations_per_epoch": 1,

        # Print more statements
        "verbose": false,

        # Whether to test and get back fitness for each epoch of training
        "test_every_epoch": false,

        # Batch size for training network
        "batch_size": 5,

        # Whether to reduce number of training examples
        "subsample": true,

        # Number of train examples to reduce to
        "subsample_amount": 5,

        # Tau value for subsampling, is a hyperparameter for controls how
        # smoothly the subsampling occurs. As tau approaches infinity, the
        # subsampling becomes uniform while it becomes highly skewed if tau
        # approaches zero. Setting tau < 0 will lead to regular ratio
        # proportionate subsampling. For details see:
        #       https://en.wikipedia.org/wiki/Softmax_function,
        # Reinforcement learning section
        "train_subsample_tau": 0.6,

        # Whether to reduce number of test examples
        "test_subsample": true,

        # Number of test examples to reduce to
        "test_subsample_amount": 5,

        # Specifies the domain's evaluator class name.
        # File will be found by snake-case of this value.
        "evaluator_class_name": "faceAgeEvaluator"
    },

    "builder_config": {

        "verbose": false,
        "min_num_pools": 5,
        "evolve_module_sharing": true,
        "module_scaling_policy": "sigmoid_module_scaling",
        "shared_layers": true,
        "layer_parameters_spec": {
            "type" : {
                "Conv2D" : {
                    "type" : {
                        "filters" : {
                            "type" : "Integer",
                            "lowerBound": 2,
                            "upperBound" : 4,
                            "scale": "log"
                        },
                        "kernel_size" : {
                            "type" : "Integer",
                            "choice" : [ 1, 3 ]
                        },
                        "activation" : {
                            "type" : "String",
                            "choice": [ "relu", "linear", "elu", "selu" ]
                        },
                        "kernel_initializer" : {
                            "type" : "String",
                            "choice": [ "glorot_normal", "he_normal",
                                        "glorot_uniform", "he_uniform" ]
                        },
                        "kernel_regularizer" : {
                            "type" : {
                                "regularizer" : {
                                    "type" : "String",
                                    "choice": [ "l2" ]
                                },
                                "l" : {
                                    "type" : "Double",
                                    "lowerBound": 1e-9,
                                    "upperBound" : 1e-3,
                                    "scale": "log"
                                }
                            }
                        },
                        "padding" : {
                            "type" : "String",
                            "choice": [ "same" ]
                        }
                    }
                },
                "Dropout" : {
                    "type" : {
                        "rate" : {
                            "type" : "Double",
                            "lowerBound": 0.0,
                            "upperBound" : 0.7,
                            "scale": "linear"
                        }
                    }
                }
            }
        },

        # List describing which layer types are *not* allowed
        # to come after another layer type, thus preventing illogical
        # layer connections, making evolution more efficient.
        #
        # Each tuple [A, B] in the list is read as "B cannot come after A".
        # The list below taken as a whole with the layer_parameter_spec above
        # basically says: "Only allow Conv2D followed by Dropout".
        "layer_mismatches": [ [ 'Conv2D', 'Conv2D' ], [ 'Dropout', 'Dropout' ], [ 'Dropout', 'Conv2D' ] ]
    },

    "blueprint_config": {

        # Blueprint population size
        "pop_size": 2,

        # Number of assembled networks to construct per blueprint
        "blueprint_num_eval": 1,

        # Number of blueprint species
        "species_size": 1,

        # Probably of adding a new connection between layer during mutation
        "prob_addconn": 1.0,

        # Probably of adding a new layer during mutation
        "prob_addnode": 1.0,

        # Percentage of top blueprints that are preserved into
        # the next generation
        "elitism": 0.0,

        # Percentage of assembled networks that are preserved into
        # the next generation
        "carry_over": 0,

        # Number of generations of random exploration before optimization.
        "preevolve_num_gen": 6,

        # Probability of adding a node in a preevolution mutation.
        "preevolve_prob_addnode": 0.7,

        # Probability of adding a connection in a preevolution mutation.
        "preevolve_prob_addconn": 0.25,
    },

    "module_config": {

        # Population size for modules
        "pop_size": 2,

        # Number of modules species
        "species_size": 1,

        # Probably of adding a new connection between layer during mutation
        "prob_addconn": 0.5,

        # Probably of adding a new layer during mutation
        "prob_addnode": 1.0,

        # Percentage of top modules that are preserved into
        # the next generation
        "elitism": 0.0,

        # Distance threshold between different module species, used for
        # determining speciation of modules
        "compatibility_threshold": 1.0
    }
}

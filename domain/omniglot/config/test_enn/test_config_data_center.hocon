{
    # The HOCON format is a JSON superset that allows comments
    # and environment variable substitution ... among other things.
    
    #
    # Small configuration for running ENN workers on in a data-center
    # environment, where an existing kubernetes cluster is ready and
    # waiting to receive work with a GoRunner instance.
    #
    # Differences in this configuration from the locally-run test_config.hocon
    # are denoted with DATA in the comments.
    #
    
    "experiment_config": {
    
        # Name of domain, allows us to determine how data should be loaded
        "domain": "omniglot",
    
        # Number of generations to run evolution for
        "num_generations": 2,
    
        # A list of tuples of different fractions of results received and
        # corresponding timeout in seconds.
        "timeout_settings": [[0.8, 1500], [0.9, 1000], [0.95, 500]],
    
        # Whether to visualize the best performing network every generation
        # and graph some attributes about the run.
        "visualize": true,
    
        # Specifies the domain-configuration class's name.
        # File will be found by snake-case of this value.
        "domain_config_class_name": "OmniglotDomainConfig",
    
        "completion_service": {
    
            # Number of workers that StudioML will spin up
            # DATA: Number of workers should be blueprint population size
            #       to minimize wall-clock time of experiment. Can be less
            #       if cost is an issue (at the expense of time)
            "num_workers": 2,
    
            # List of requirements for worker machines, including number of
            # CPUs, GPUs needed, RAM, HDD space.
            #            
            # DATA: increase ram, hdd, gpus
            "resources_needed": { 
                "cpus": 1,
                "ram": "8g",
                "hdd": "30g",
                "gpus": 1,
                "gpuMem": "5g"
            }
    
            # Timeout for completion service
            "timeout": 300,
    
            # Cloud settings for completion service
            "cloud": null,
    
            # Whether the completion service is running locally or not
            # DATA: change to false
            "local": false,

            # DATA: Which queue to submit jobs to.
            #       Rabbit MQ names *must* begin with "rmq_"
            "queue": rmq_${ENN_USER}_test_config,
    
            "studio_ml_config": {

                # AWS: May 2019, S3 Bucket Name Requirements listed
                # - bucket name can be between 3 and 63 characters long
                # - contain only lower-case characters, numbers, periods, and dashes
                # - Link: https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-s3-bucket-naming-requirements.html
                "database": {
                    "type": "s3",
                    "endpoint": ${STUDIO_DATABASE_ENDPOINT},
                    "bucket": ${ENN_USER}-enn-studioml-database,
                    "authentication": "none"
                },
                "storage": {
                    "type": "s3",
                    "endpoint": ${STUDIO_STORAGE_ENDPOINT},
                    "bucket": ${ENN_USER}-enn-studioml-storage
                },

                # DATA: server section added
                "server": {
                    "authentication": "None"
                },

                # DATA: env section added
                #
                # What this next 'env' section does is tells Studio ML to send
                # your credentials and the region information (in the
                # environment in which you are running the Experiment Host/
                # session_server) over whatever wire you happen to be using
                # (local, network to AWS, GCloud, etc) to be picked up by the
                # Studio ML distributed workers to set the same environment
                # variables and values in which the python NN evaluation is run in on
                # whatever machine they happen to be running on.
                "env": {
                    "AWS_ACCESS_KEY_ID": ${AWS_ACCESS_KEY_ID},
                    "AWS_SECRET_ACCESS_KEY": ${AWS_SECRET_ACCESS_KEY},

                    # Set your own environment for this domain:
                    # export AWS_DEFAULT_REGION="us-west-2"
                    "AWS_DEFAULT_REGION": ${AWS_DEFAULT_REGION},
                    "PATH": "%PATH%:./bin"
                },

                # DATA: add cloud section with address of RMQ
                #       you will need to export these variables in your environment:
                #       export RMQ_USER=<your_rmq_username>
                #       export RMQ_PASSWORD=<your_rmq_password>
                #       export RMQ_HOST=<your_rmq_host>
                #       export RMQ_PORT=<your_rmq_port>
                "cloud": {
                    "queue": {
                        "rmq": "amqp://"${RMQ_USER}":"${RMQ_PASSWORD}"@"${RMQ_HOST}":"${RMQ_PORT}"/%2f?connection_attempts=30&retry_delay=1&socket_timeout=15"
                    }
                }

                # DATA: no "queue" key

                "saveMetricsFrequency": "1m",
                "saveWorkspaceFrequency": "1m",
                "verbose": "error"
            }
        }
    },
    
    "domain_config": {

        # Use smaller test data set
        "use_test_data": true,
    
        # Number of tasks to train on for omniglot (20 by default)
        "num_tasks": 2,
    
        # Name of split set to use for determining fitness during evolution, 
        # either "val" or "test"
        "test_dataset": "val",
    
        # Whether to extract the omniglot data files in current directory or /tmp/
        "unzip_curr_dir": false,
    
        # URL to omniglot data files
        "data_basedir": ${DOMAIN_DATA_ENDPOINT}/ml-enn/deepbilevel_datafiles/omniglot,
    
        # Number of epochs of training during evaluation
        "num_epochs": 2,
    
        # Number of minibatches per epoch
        "num_iterations_per_epoch": 2,
    
        # Print more statements
        "verbose": true,
    
        # Whether to test and get back fitness for each epoch of training
        "test_every_epoch": false,
    
        # Specifies the domain's evaluator class name.
        # File will be found by snake-case of this value.
        "evaluator_class_name": "OmniglotEvaluator"
    },
    

    "builder_config": {

        # A JSON structure describing the evolutionary bounds for parameters
        # that are evolved alongside the evolved architecture.  These can be
        # any composed structure you want where fields include:
        #   * scalar ranges of doubles, integers
        #   * scalar enums of doubles, integers, booleans, strings 
        #   * lists of scalars, lists, and structures
        #   * structures composed of any of the above.
        # See the README-specs.md for more details as to the specification.
        "evaluation_hyperparameters_spec": {
            "type" : {
                "learning_rate" : {
                    "type" : "Double",
                    "lowerBound": 1e-4,
                    "upperBound" : 1e-3,
                    "scale": "log"
                }
            }
        },

        # Nested evolved structure spec describing the layers of the network
        # architecture that are to be evolved.
        #
        # The outermost structure describes the set of layer types that
        # can be used.
        #
        # The next level of structure describes the evolutionary boundaries for
        # each parameter in a particular Keras layer with one field per Keras
        # layer argument. Any layer argument not described is held to its
        # default value as per the Keras documentation. If you want to hold a
        # particular layer argument constant to a non-default value, describe
        # that here as an enum with only one choice.
        #
        # Again, see README-spec.md for more details.
        "layer_parameters_spec": {
            "type" : {
                "Conv2D" : {
                    "type" : {
                        "filters" : {
                            "type" : "Integer",
                            "lowerBound": 16,
                            "upperBound" : 96,
                            "scale": "log"
                        },
                        "kernel_size" : {
                            "type" : "Integer",
                            "choice" : [ 1, 3 ]
                        },
                        "activation" : {
                            "type" : "String",
                            "choice": [ "relu", "linear", "elu", "selu" ]
                        },
                        "kernel_initializer" : {
                            "type" : "String",
                            "choice": [ "glorot_normal", "he_normal",
                                        "glorot_uniform", "he_uniform" ]
                        },
                        "kernel_regularizer" : {
                            "type" : {
                                "regularizer" : {
                                    "type" : "String",
                                    "choice": [ "l2" ]
                                },
                                "l" : {
                                    "type" : "Double",
                                    "lowerBound": 1e-9,
                                    "upperBound" : 1e-3,
                                    "scale": "log"
                                }
                            }
                        },
                        "padding" : {
                            "type" : "String",
                            "choice": [ "same" ]
                        }
                    }
                },
                "Dropout" : {
                    "type" : {
                        "rate" : {
                            "type" : "Double",
                            "lowerBound": 0.0,
                            "upperBound" : 0.7,
                            "scale": "linear"
                        }
                    }
                }
            }
        },

        # List describing which layer types are *not* allowed
        # to come after another layer type, thus preventing illogical
        # layer connections, making evolution more efficient.
        #
        # Each tuple [A, B] in the list is read as "B cannot come after A".
        # The list below taken as a whole with the layer_parameter_spec above
        # basically says: "Only allow Conv2D followed by Dropout".
        "layer_mismatches": [ [ 'Conv2D', 'Conv2D' ], [ 'Dropout', 'Dropout' ], [ 'Dropout', 'Conv2D' ] ],

        # Choices are "softmax_module_scaling" and "sigmoid_module_scaling"
        "module_scaling_policy": "softmax_module_scaling",

        # Choices are "keras_zero_padding_image" and "null" 
        "encoder": "keras_zero_padding_image",

        # Choices are "keras_classifier", "keras_global_pooling_classifier"
        # and "null" 
        "decoder": "keras_classifier"
    },

    
    "blueprint_config": {
    
        # Blueprint population size
        "pop_size": 2,
    
        # Number of assembled networks to construct per blueprint
        "blueprint_num_eval": 1,
    
        # Number of blueprint species
        "species_size": 1,
    
        # Probability of adding a new connection between layer during mutation
        "prob_addconn": 1.0,
    
        # Probability of adding a new layer during mutation
        "prob_addnode": 1.0,
    
        # Percentage of top blueprints that are preserved into the next generation
        "elitism": 0.0,
    
        # Percentage of assembled networks that are preserved
        # into the next generation
        "carry_over": 0
    },
    
    
    "module_config": {
    
        # Population size for modules
        "pop_size": 2,
    
        # Number of modules species
        "species_size": 2,
    
        # Probability of adding a new connection between layer during mutation
        "prob_addconn": 0.5,
    
        # Probability of adding a new layer during mutation
        "prob_addnode": 1.0,
    
        # Percentage of top modules that are preserved into the next generation
        "elitism": 0.0,
    
        # Distance threshold between different module species, used for
        # determining speciation of modules
        "compatibility_threshold": 1.0
    }
} 
